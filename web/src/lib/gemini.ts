import { GoogleGenerativeAI, GenerativeModel, Content } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.NEXT_PUBLIC_GEMINI_API_KEY!);

function getModel(): GenerativeModel {
    return genAI.getGenerativeModel({
        model: process.env.NEXT_PUBLIC_GEMINI_MODEL || 'gemini-1.5-flash'
    });
}

// MARK: - Chat Message Type for History
export interface ChatHistoryMessage {
    role: 'user' | 'model';
    text: string;
}

// MARK: - Enhanced Prompt Builder (NotebookLM-Style)
function buildEnhancedPrompt(message: string, context: string): string {
    return `${context}

---

## KullanÄ±cÄ± Sorusu
${message}

---

## YanÄ±t KurallarÄ±

### 1. Kaynak KullanÄ±mÄ± ve Dil Uyumu
- **SADECE** yukarÄ±daki dokÃ¼man bÃ¶lÃ¼mlerini kullan
- DÄ±ÅŸ bilgi veya varsayÄ±m YAPMA
- **Ã–NEMLÄ°**: DokÃ¼man Ä°ngilizce, soru TÃ¼rkÃ§e olabilir:
  * Ä°ngilizce terimlerin TÃ¼rkÃ§e karÅŸÄ±lÄ±klarÄ±nÄ± kullanarak yanÄ±tla
  * Ã–rnek: "long spine board" â†’ "uzun sÄ±rt tahtasÄ±" veya "travma tahtasÄ±"
  * Hem orijinal terimi hem TÃ¼rkÃ§e karÅŸÄ±lÄ±ÄŸÄ± belirt
- Her Ã¶nemli bilgi iÃ§in kaynak gÃ¶ster: [1], [2] veya [Sayfa X]

### 2. YanÄ±t FormatÄ±
- **KÄ±sa soru** â†’ Ã–z ve net cevap (1-3 cÃ¼mle)
- **AÃ§Ä±klama istekleri** â†’ YapÄ±landÄ±rÄ±lmÄ±ÅŸ maddeler halinde
- **KarÅŸÄ±laÅŸtÄ±rma** â†’ Tablo formatÄ± kullan
- **TanÄ±m sorularÄ±** â†’ Ã–nce tanÄ±m, sonra detay

### 3. Belirsizlik Durumu
EÄŸer konu dokÃ¼manda YOKSA:
- "Bu konuda dokÃ¼man bilgi iÃ§ermiyor." de
- Varsa ilgili/yakÄ±n konularÄ± Ã¶ner: "Ancak Sayfa X'te ilgili konu ele alÄ±nÄ±yor: ..."
- **NOT**: Ä°ngilizce terimler iÃ§in TÃ¼rkÃ§e karÅŸÄ±lÄ±klarÄ± dÃ¼ÅŸÃ¼n!
  * "spinal board", "backboard" â†’ "sÄ±rt tahtasÄ±", "travma tahtasÄ±", "omurga tahtasÄ±"
  * "cardiac arrest" â†’ "kalp durmasÄ±", "kardiyak arrest"
- ASLA uydurma bilgi verme

### 4. Dil ve Ton
- Akademik ama anlaÅŸÄ±lÄ±r TÃ¼rkÃ§e
- Teknik terimleri hem Ä°ngilizce hem TÃ¼rkÃ§e ver
- Ã–rnek: "Long spine board (uzun sÄ±rt tahtasÄ±)..."
- Gereksiz tekrardan kaÃ§Ä±n

Åžimdi yukarÄ±daki kurallara uyarak, Ã¶zellikle Ã§apraz dil eÅŸleÅŸtirmesine dikkat ederek soruyu yanÄ±tla:`;
}

// MARK: - Build Context Header (matches mobile)
function buildContextHeader(): string {
    return `# DokÃ¼man BÃ¶lÃ¼mleri
AÅŸaÄŸÄ±da kullanÄ±cÄ±nÄ±n sorusuyla ilgili dokÃ¼man bÃ¶lÃ¼mleri yer almaktadÄ±r.

`;
}

// MARK: - Convert history to Gemini format
function historyToGeminiFormat(history: ChatHistoryMessage[]): Content[] {
    return history.map(msg => ({
        role: msg.role,
        parts: [{ text: msg.text }]
    }));
}

// Translation
export async function translateText(
    text: string,
    targetLang: string = 'tr'
): Promise<string> {
    const model = getModel();
    const prompt = `Translate the following text to ${targetLang}. Only return the translation, nothing else:\n\n${text}`;

    const result = await model.generateContent(prompt);
    return result.response.text();
}

/**
 * Sorgunun Ä°ngilizce'ye Ã§evrilmesi gerekip gerekmediÄŸini akÄ±llÄ±ca belirler.
 * YapÄ±sal referanslarÄ± (Tablo, Åžekil, BÃ¶lÃ¼m + rakamlar) korur.
 */
function shouldTranslateQuery(query: string): boolean {
    // Tablo/Åžekil/BÃ¶lÃ¼m referanslarÄ± asla Ã§evrilmemeli
    // Ã–rnekler: "Tablo 2-1", "Åžekil 3.4", "BÃ¶lÃ¼m 5", "Table 2-1"
    const structuralPatterns = /\b(tablo|ÅŸekil|bÃ¶lÃ¼m|sayfa|chapter|table|figure|section)\s*[\d.-]+/i;
    if (structuralPatterns.test(query)) {
        console.log(`ðŸ”’ Query contains structural reference, skipping translation: "${query}"`);
        return false;
    }
    
    // Ã‡ok kÄ±sa sorgularÄ± Ã§evirme (3 kelime veya daha az)
    const wordCount = query.trim().split(/\s+/).length;
    if (wordCount <= 3) {
        console.log(`ðŸ”’ Query too short (${wordCount} words), skipping translation: "${query}"`);
        return false;
    }
    
    // KarmaÅŸÄ±k tÄ±bbi/teknik terimler varsa Ã§evir
    const complexTerms = /\b(kardiyovaskÃ¼ler|pulmoner|nÃ¶rolojik|travma|resÃ¼sitasyon|patofizyoloji|farmakoloji)\b/i;
    if (complexTerms.test(query)) {
        console.log(`ðŸ”„ Query contains complex medical terms, will translate: "${query}"`);
        return true;
    }
    
    // VarsayÄ±lan: TÃ¼rkÃ§e karakter varsa ama yapÄ±sal referans yoksa Ã§evirme
    // Basit sorular iÃ§in direkt TÃ¼rkÃ§e arama daha iyi sonuÃ§ verir
    console.log(`ðŸ”’ Using original query without translation: "${query}"`);
    return false;
}

/**
 * Sorguyu Ä°ngilizce'ye Ã§evirir ve tÄ±bbi/teknik terimlerle geniÅŸletir
 * RAG iÃ§in daha iyi sonuÃ§lar alÄ±nmasÄ±nÄ± saÄŸlar
 */
export async function translateAndExpandQuery(query: string): Promise<string> {
    const model = getModel();
    
    const prompt = `Sen bir tÄ±bbi terminoloji uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki TÃ¼rkÃ§e sorguyu Ä°ngilizce'ye Ã§evir ve tÄ±bbi terimlerle geniÅŸlet.

TÃ¼rkÃ§e sorgu: "${query}"

Kurallar:
1. Ã–nce direkt Ä°ngilizce Ã§eviri yap
2. TÄ±bbi terimlerin alternatif isimlerini ekle
3. KÄ±sa ve Ã¶z tut (maksimum 10 kelime)
4. SADECE terimleri ver, aÃ§Ä±klama yapma

Ã–rnekler:
- "sÄ±rt tahtasÄ± nedir" â†’ "backboard spinal board spine board immobilization"
- "kalp durmasÄ± tedavisi" â†’ "cardiac arrest resuscitation CPR treatment"
- "vazopressÃ¶r dozlarÄ±" â†’ "vasopressor doses epinephrine norepinephrine"

Åžimdi yukarÄ±daki sorguyu Ã§evir ve geniÅŸlet (SADECE terimleri ver):`;

    try {
        const result = await model.generateContent(prompt);
        const expandedQuery = result.response.text().trim();
        console.log(`ðŸ”„ Query expansion: "${query}" â†’ "${expandedQuery}"`);
        return expandedQuery;
    } catch (error) {
        console.error('Query expansion failed:', error);
        // Fallback: basit Ã§eviri
        return query;
    }
}

// Chat with context
export async function chatWithContext(
    message: string,
    context: string
): Promise<string> {
    const model = getModel();
    const prompt = `You are a helpful assistant analyzing a document. Use the following context to answer the question.

Context from document:
${context}

User question: ${message}

Please provide a helpful, accurate answer based on the context. If the answer cannot be found in the context, say so clearly.`;

    const result = await model.generateContent(prompt);
    return result.response.text();
}

// Document summary
export async function generateSummary(text: string): Promise<string> {
    const model = getModel();
    const prompt = `Summarize the following document text in Turkish. Keep it concise but comprehensive:\n\n${text}`;

    const result = await model.generateContent(prompt);
    return result.response.text();
}

// Smart note from selection
export async function generateSmartNote(text: string): Promise<string> {
    const model = getModel();
    const prompt = `Read this text and generate a smart note in Turkish. Include key points, important concepts, and any notable insights:\n\n${text}`;

    const result = await model.generateContent(prompt);
    return result.response.text();
}

// Stream chat (for real-time responses)
export async function* streamChat(
    message: string,
    context?: string
): AsyncGenerator<string, void, unknown> {
    const model = getModel();

    const prompt = context
        ? `Context from document:\n${context}\n\nUser question: ${message}\n\nProvide a helpful answer based on the context.`
        : message;

    const result = await model.generateContentStream(prompt);

    for await (const chunk of result.stream) {
        yield chunk.text();
    }
}

// Stream chat with dynamic RAG search (for document-aware responses)
// DEPRECATED: Use streamChatWithRAGAndHistory instead for memory support
export async function* streamChatWithRAG(
    message: string,
    fileId: string
): AsyncGenerator<string, void, unknown> {
    // Forward to new function with empty history for backward compatibility
    yield* streamChatWithRAGAndHistory(message, fileId, []);
}

// MARK: - Stream Chat with RAG + Conversation History (Memory Support)
// Bu fonksiyon hem RAG hem de Ã¶nceki mesajlarÄ± hatÄ±rlama Ã¶zelliÄŸi saÄŸlar
export async function* streamChatWithRAGAndHistory(
    message: string,
    fileId: string,
    history: ChatHistoryMessage[]
): AsyncGenerator<string, void, unknown> {
    // Dynamic import to avoid circular dependency
    const { searchRelevantChunksHybrid } = await import('./rag');

    // GÃœNCELLEME: Sadece karmaÅŸÄ±k sorgularÄ± Ã§evir/geniÅŸlet, yapÄ±sal referanslarÄ± koru
    let searchQuery = message;
    const hasTurkishChars = /[Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄžÄ°Ã–ÅžÃœ]/.test(message);
    
    // AkÄ±llÄ± Ã§eviri: "Tablo 2-1" gibi referanslarÄ± korur
    if (hasTurkishChars && shouldTranslateQuery(message)) {
        try {
            searchQuery = await translateAndExpandQuery(message);
            console.log(`ðŸ“ Using expanded query for RAG: "${searchQuery}"`);
        } catch (error) {
            console.warn('Query expansion failed, using original:', error);
            searchQuery = message;
        }
    } else {
        console.log(`ðŸ“ Using original query for RAG: "${searchQuery}"`);
    }

    // Search for relevant chunks using hybrid search
    const context = await searchRelevantChunksHybrid(fileId, searchQuery, 10);

    const model = getModel();

    // Build context with header
    const formattedContext = context
        ? buildContextHeader() + context
        : '';

    // Build enhanced prompt
    const prompt = formattedContext
        ? buildEnhancedPrompt(message, formattedContext)
        : message;

    // If we have conversation history, use chat session for memory
    if (history.length > 0) {
        // Convert history to Gemini format
        const geminiHistory = historyToGeminiFormat(history);

        // Start chat with history
        const chat = model.startChat({
            history: geminiHistory
        });

        // Send new message with streaming
        const result = await chat.sendMessageStream(prompt);

        for await (const chunk of result.stream) {
            yield chunk.text();
        }
    } else {
        // No history - use simple generate
        const result = await model.generateContentStream(prompt);

        for await (const chunk of result.stream) {
            yield chunk.text();
        }
    }
}


// Chat with image - for image-based questions
export async function chatWithImage(
    message: string,
    imageBase64: string,
    context?: string
): Promise<string> {
    const model = getModel();

    // Extract base64 data (remove data URL prefix if present)
    const base64Data = imageBase64.includes(',')
        ? imageBase64.split(',')[1]
        : imageBase64;

    // Detect mime type from data URL or default to PNG
    let mimeType = 'image/png';
    if (imageBase64.startsWith('data:')) {
        const match = imageBase64.match(/data:([^;]+);/);
        if (match) mimeType = match[1];
    }

    const imagePart = {
        inlineData: {
            mimeType,
            data: base64Data,
        },
    };

    const textPrompt = context
        ? `DÃ¶kÃ¼man baÄŸlamÄ±:\n${context}\n\nKullanÄ±cÄ± sorusu: ${message}\n\nLÃ¼tfen gÃ¶rseli analiz ederek soruyu yanÄ±tla.`
        : message;

    const result = await model.generateContent([textPrompt, imagePart]);
    return result.response.text();
}

// Stream chat with image - for real-time responses with image
export async function* streamChatWithImage(
    message: string,
    imageBase64: string,
    context?: string
): AsyncGenerator<string, void, unknown> {
    const model = getModel();

    // Extract base64 data
    const base64Data = imageBase64.includes(',')
        ? imageBase64.split(',')[1]
        : imageBase64;

    // Detect mime type
    let mimeType = 'image/png';
    if (imageBase64.startsWith('data:')) {
        const match = imageBase64.match(/data:([^;]+);/);
        if (match) mimeType = match[1];
    }

    const imagePart = {
        inlineData: {
            mimeType,
            data: base64Data,
        },
    };

    const textPrompt = context
        ? `DÃ¶kÃ¼man baÄŸlamÄ±:\n${context}\n\nKullanÄ±cÄ± sorusu: ${message}\n\nLÃ¼tfen gÃ¶rseli analiz ederek soruyu yanÄ±tla.`
        : message;

    const result = await model.generateContentStream([textPrompt, imagePart]);

    for await (const chunk of result.stream) {
        yield chunk.text();
    }
}
